* Hi, this is the rmd file for project 2. We will be doing logistic regression to model food insecurity



```{r, echo=FALSE, cache=TRUE }
Food_Sec <- data.frame(read.csv("dec21pub.csv"))
```



```{r, echo=FALSE, results='hide', message=FALSE}
library(dplyr)
library(ezids)
library(ggplot2)
library(epiR)
library(pROC)
```

* Lets start with the variables we selected for the first project. We should replace some variables I think, but we'll do it along the way. I am just copying code from the first project for now. so we can get a base to build upon.

```{r, results='markup', echo=FALSE}


FS_Subset <- subset(Food_Sec, HRINTSTA == 001 & HRSUPINT == 001 & HRFS12MD != -9)
FS_Subset <- subset(FS_Subset, select = c(	"GESTFIPS",	"HRNUMHOU",	"HEFAMINC",	"HESP1",	"PTDTRACE",	"PRCITSHP",	"PEMJNUM",	"PEHRUSL1",	"PEEDUCA", "PRNMCHLD" , "HRFS12MD"))

  

FS_Subset <- FS_Subset %>% rename("States" = "GESTFIPS", "Family_Size" = "HRNUMHOU",	"Household_Income" = "HEFAMINC",	"SNAP" = "HESP1",	"Ethnicity" =	"PTDTRACE", "Citizenship_status" = "PRCITSHP",	"Number_of_Jobs" = "PEMJNUM",	"Hours_on_Jobs" = "PEHRUSL1" , "Education_Level" = "PEEDUCA" , "Number_of_children" = "PRNMCHLD",  "FoodSecurity_score" = "HRFS12MD")



## Converting the all the columns to factors as they are all ordinal(except the Id, but since it's categorical i'm converting it into a factor too)


FS_Subset[] <- lapply( FS_Subset, factor)

str(FS_Subset)

```



* Since we will be doing logistic regression, we have to reduce our response to two levels(binary). If we complete this project before the deadline we can look into multinomial regression as well.




```{r, results='markup', echo=FALSE, results='hide'}
levels(FS_Subset$'FoodSecurity_score') <- c( "High Food Security", "Marginal Food Security", "Low Food Security", "Very Low Food Security")


FS_Subset$FS_Status <- FS_Subset$FoodSecurity_score

levels(FS_Subset$FS_Status) <- c( "Food Secure", "Food Secure", "Food Insecure", "Food Insecure")

levels(FS_Subset$'Ethnicity') <- c('White only', 'Black only', 'American Indian, Alaskan native only', 'Asian Only', 'Hawaiian', 'White-black', 'White-AI', 'White-Asian', 'White-HP', 'Black-AI', 'Black-Asian', 'Black-HP', 'AI-Asian', 'AI-HP', 'Asian-HP', 'W-B-AI', 'W-B-A', 'W-B-HP', 'W-AI-A', 'W-AI-HP', 'W-A-HP', 'B-AI-A', 'W-B-AL-A', 'W-AI-A-HP', 'Other 3 race combo', 'Other 4 and 5 race combo')






levels(FS_Subset$'Citizenship_status') <- c('NATIVE, BORN IN THE UNITED STATES', 'NATIVE, BORN IN PUERTO RICO OR OTHER U.S. ISLAND AREAS', 'NATIVE, BORN ABROAD OF AMERICAN PARENT OR PARENTS', 'FOREIGN BORN, U.S. CITIZEN BY NATURALIZATION', 'FOREIGN BORN, NOT A CITIZEN OF THE UNITED STATES')
summary(FS_Subset$'Citizenship_status', title = "PRCITSHP")







```
* Splitting the data

```{r, results ='markup'}
set.seed(1)

sample <- sample(c(TRUE, FALSE), nrow(FS_Subset), replace = TRUE, prob = c(0.6, 0.4))

train <- FS_Subset[sample, ]
test  <- FS_Subset[!sample, ]

str(test)
str(train)
```

* Just adding all the variables in the in the logistic regression to see what happens.We can then take out some predictors and add others or add interaction terms. This will also serve as sample code if you all are stuck somewhere.


```{r, results='markup'}
logistic <- glm(FS_Status ~ States + Family_Size + Household_Income + SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = train, family = "binomial")

summary(logistic)


```

* predicting on the testing data and finding the mean squared error for this model.

```{r, results='markup'}

logistic_model1.prob <- predict(logistic, test, type = "response")
logistic_model1.pred = rep("Food Secure", dim(test)[1])
logistic_model1.pred[logistic_model1.prob > .5] = "Food Insecure"

mean(logistic_model1.pred == test$FS_Status)

table(logistic_model1.pred, test$FS_Status)
```
* Our precision for this model is `r 91/(91+94)`

* Our recall for this model is `r 91/(91+2762)`

* In my opinion, recall is more important to us as we want to get our false negative down as much as possible. False positives are inclusion errors, while false negatives are exclusion errors. It's better if we are able to more accurately identify who all are food insecure and need of aid rather than identifying who all are not food insecure and hence don't need aid.

```{r, results='markup'}
test$logistic_model1.prob <- logistic_model1.prob
roc_model1 <- roc(FS_Status ~ logistic_model1.prob, data = test)
plot(roc_model1)
auc(roc_model1)

```

```{r results='markup'}
sum(test$FS_Status == "Food Secure")/sum(test$FS_Status == "Food Insecure")

```

* So, our model has a 90% classification rate but the ratio of Food secure to Insecure in our data is 9.04. so this is a terrible model that's as good as tossing a coin. We will have to do something about the imbalance in our response and will have to clean our data further. Since all our variables are categorical of some kind, I highly recommend reading about categorical data modelling to figure out what to do.

* I think doing one-hot encoding(dummy variable) will help in dealing with the level issues in our predictors. We should also combine similar levels so we can reduce the number of levels. also the negative values which correspond to not in the universe or similar have to be dealt with in someway. we can either choose to omit those observation or try to find a proxy for them. I will prefer the latter.

* For the response variable imbalance we can create a new samples where the distribution between the responses is equal. Maybe something like k-fold Cross-Validation would work but I am not sure and would have to read more about it. 



#### I am going to be adding weights to the data so our minority class, which is food insecurity, affects the model more.


```{r, results='markup'}
weight_minority_class = sum(FS_Subset$FS_Status == "Food Secure")/sum(FS_Subset$FS_Status == "Food Insecure")
for(i in seq_len(NROW(FS_Subset))){
  
if(FS_Subset$FS_Status[i] == "Food Insecure"){
  FS_Subset$Weight[i] = weight_minority_class

}
  else
    FS_Subset$Weight[i] = 1
}

FS_Subset$Weight <- as.numeric(FS_Subset$Weight)
summary(FS_Subset$Weight)

## Splitting again because train and test doesn't contain the weight column

set.seed(1)

sample <- sample(c(TRUE, FALSE), nrow(FS_Subset), replace = TRUE, prob = c(0.6, 0.4))

train <- FS_Subset[sample, ]
test  <- FS_Subset[!sample, ]


logistic_weighted <- glm(FS_Status ~ States + Family_Size + Household_Income + SNAP + Citizenship_status + Number_of_Jobs + Education_Level   , data = train,  weights = Weight, family = "binomial")

summary(logistic_weighted)






```

```{r, results='markup'}

logistic_model2.prob <- predict(logistic_weighted, test, type = "response")
logistic_model2.pred = rep("Food Secure", dim(test)[1])
logistic_model2.pred[logistic_model2.prob > .5] = "Food Insecure"

mean(logistic_model2.pred == test$FS_Status)

table(logistic_model2.pred, test$FS_Status)
```
* Our precision for this model is `r 2702/(2707+7445)`

* Our recall for this model is `r 2702/(2707+146)`

* As you can see even though our classification rate of the model went down and the precision of model went down drastically, we were able to raise our recall rate significantly. 

```{r, results='markup'}
test$logistic_model2.prob <- logistic_model2.prob
roc_model2 <- roc(FS_Status ~ logistic_model2.prob, data = test)
plot(roc_model2)
auc(roc_model2)


```


***

* I think this is enough for logistic regression. We can try changing and adding more predictors, but largely i think this is enough. I wasn't abe to add a lot of important predictors like ethnicity as the model was giving some errors. We should try to figure out how to solve it.

* We are going to try to do random forests and KNN now.

* Working on the data is still our number 1 priority, if we can figure out factor selection and how to use the factors we can't use rn, that would be more helpful than just getting the model to work.

